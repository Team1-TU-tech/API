from kafka import KafkaConsumer
import json
import pandas as pd
import pyarrow as pa
import pyarrow.parquet as pq
import boto3
import os, time
from io import BytesIO
from dotenv import load_dotenv
from datetime import datetime, timedelta
import logging
from collections import defaultdict
import threading

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

# .env íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ í™˜ê²½ ë³€ìˆ˜ ì½ê¸°
load_dotenv()

KAFKA_SERVER = os.getenv("KAFKA_SERVER")

# Kafka consumer ì„¤ì •
consumer = KafkaConsumer(
    #'logs',
    bootstrap_servers=KAFKA_SERVER,
    group_id='log-consumer-group',
    enable_auto_commit=False,  # ìˆ˜ë™ ì˜¤í”„ì…‹ ì»¤ë°‹ ì„¤ì •
    auto_offset_reset='latest',  # 'earliest' ë˜ëŠ” 'latest' ì„¤ì •
    value_deserializer=lambda m: json.loads(m.decode('utf-8'))
)
# ì—¬ëŸ¬ í† í”½ì„ êµ¬ë…
consumer.subscribe(['Validate', 'Login_log', 'Logout_log', 'KakaoLogin_log', 'KakaoLogout_log', 'Signup_log', 'View_detail_log' , 'Search_log'])

# S3 í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
s3 = boto3.client('s3',
    aws_access_key_id=os.getenv("AWS_ACCESS_KEY_ID"),
    aws_secret_access_key=os.getenv("AWS_SECRET_ACCESS_KEY"),
    region_name="ap-northeast-2"
    )

# ê° í† í”½ì— ëŒ€í•œ ë©”ì‹œì§€ì™€ íƒ€ì´ë¨¸ë¥¼ ì €ì¥í•˜ëŠ” ë”•ì…”ë„ˆë¦¬
topics_data = {}
countdown_timers = {}

# í† í”½ë³„ ë©”ì‹œì§€ ìˆ˜
topic_message_count = {}
total_message_count = 0  # ëª¨ë“  í† í”½ì˜ ë©”ì‹œì§€ í•©ì‚° ì¹´ìš´íŠ¸

# ë©”ì‹œì§€ë¥¼ ìˆ˜ì‹ í•˜ê³  ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜
def consume_message(message):

    global total_message_count

    topic = message.topic
    log_message = message.value

    # ê° í† í”½ë³„ë¡œ ë©”ì‹œì§€ ì²˜ë¦¬ ì‹œì‘
    if topic not in topics_data:
        topics_data[topic] = []
        topic_message_count[topic] = 0  # ì¹´ìš´íŠ¸ë¥¼ ì´ˆê¸°í™”

    # ìƒˆë¡œìš´ ë©”ì‹œì§€ë¥¼ ìŒ“ëŠ”ë‹¤
    topics_data[topic].append(log_message)
    topic_message_count[topic] += 1  # ë©”ì‹œì§€ ìˆ˜ ì¹´ìš´íŠ¸
    total_message_count += 1  # ì „ì²´ ë©”ì‹œì§€ ìˆ˜ ì¹´ìš´íŠ¸ ì¦ê°€
    
    # ì²« ë²ˆì§¸ ë©”ì‹œì§€ì¼ ê²½ìš° ì¹´ìš´íŠ¸ë‹¤ìš´ ì‹œì‘
    if topic not in countdown_timers or not countdown_timers[topic].is_alive():
        countdown_timers[topic] = threading.Timer(3600.0, upload_to_s3, args=[topic])
        countdown_timers[topic].start()

    # # ë©”ì‹œì§€ê°€ ì¶”ê°€ë  ë•Œë§ˆë‹¤ íƒ€ì´ë¨¸ë¥¼ ìƒˆë¡œ ì‹œì‘í•´ì„œ 60ì´ˆ í›„ì— ì—…ë¡œë“œ
    # countdown_timers[topic].cancel()
    # countdown_timers[topic] = threading.Timer(60.0, upload_to_s3, args=[topic])
    # countdown_timers[topic].start()

    # ë©”ì‹œì§€ ìˆ˜ê°€ 1000ê°œ ì´ìƒì´ë©´ ê° í† í”½ìœ¼ë¡œ S3ì— ì—…ë¡œë“œ
    if total_message_count >= 1000:
        upload_all_to_s3()


# S3ì— ì—…ë¡œë“œí•˜ëŠ” í•¨ìˆ˜ (ëª¨ë“  í† í”½ì— ëŒ€í•´ ì—…ë¡œë“œ)
def upload_all_to_s3():
    global total_message_count

    for topic, log_messages in topics_data.items():
        if log_messages:  # ë©”ì‹œì§€ê°€ ìˆì„ ë•Œë§Œ ì—…ë¡œë“œ
            upload_to_s3(topic)

    # ëª¨ë“  í† í”½ ì—…ë¡œë“œ í›„ ì „ì²´ ë©”ì‹œì§€ ìˆ˜ ì´ˆê¸°í™”
    total_message_count = 0

    
# S3ì— ì—…ë¡œë“œí•˜ëŠ” í•¨ìˆ˜
def upload_to_s3(topic):
    global total_message_count

    # ì—…ë¡œë“œí•  ë©”ì‹œì§€ë¥¼ ê°€ì ¸ì˜¤ê¸°
    log_messages = topics_data[topic]
    num_messages = len(log_messages)  # ì—…ë¡œë“œí•œ ë©”ì‹œì§€ ìˆ˜

    # DataFrameìœ¼ë¡œ ë³€í™˜
    df = pd.json_normalize(log_messages)

    # DataFrameì„ Parquet í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    table = pa.Table.from_pandas(df)

    # ë©”ëª¨ë¦¬ ë²„í¼ì— Parquet íŒŒì¼ì„ ì €ì¥
    buffer = BytesIO()
    pq.write_table(table, buffer)
    buffer.seek(0)  # ë²„í¼ì˜ ì²˜ìŒìœ¼ë¡œ ì´ë™

    # í˜„ì¬ ì‹œê°„ì„ ê¸°ì¤€ìœ¼ë¡œ íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±
    kst_time = datetime.utcnow() + timedelta(hours=9)
    timestamp = kst_time.strftime("%Y-%m-%d_%H-%M")  # ë¶„ í¬í•¨í•œ íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±

    # S3 ì—…ë¡œë“œ
    s3.put_object(
        Bucket='t1-tu-data',
        Key=f'logs/{topic}/{timestamp}.parquet',  # ê° í† í”½ë³„ë¡œ ê²½ë¡œë¥¼ ë‹¤ë¥´ê²Œ ì„¤ì •
        Body=buffer
    )

    # ì—…ë¡œë“œ í›„ ì´ˆê¸°í™”
    logger = logging.getLogger()
    logger.info(f'ğŸ¢ğŸ¢ğŸ¢ğŸ¢ğŸ¢ğŸ¢ğŸ¢ğŸ¢ğŸ¢ğŸ¢ ë¡œê·¸ê°€ S3ì— ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤: logs/{topic}/{timestamp}.parquet ğŸ¢ğŸ¢ğŸ¢ğŸ¢ğŸ¢ğŸ¢ğŸ¢ğŸ¢ğŸ¢ğŸ¢')

    # ì—…ë¡œë“œí•œ ë©”ì‹œì§€ì™€ ì¹´ìš´íŠ¸ ì´ˆê¸°í™”
    topics_data[topic] = []  # ë©”ì‹œì§€ ì´ˆê¸°í™”
    topic_message_count[topic] = 0  # ë©”ì‹œì§€ ìˆ˜ ì´ˆê¸°í™”
    
    total_message_count -= num_messages # ì´ë¯¸ ì²˜ë¦¬ëœ ë©”ì„¸ì§€ê°€ í•©ì‚° ê¸°ì¤€ì— í¬í•¨ë˜ì–´ ì¤‘ë³µ ì—…ë¡œë“œê°€ ì´ë£¨ì–´ì§€ì§€ ì•Šê²Œë”ë”

    if topic in countdown_timers:
        countdown_timers[topic].cancel()  # íƒ€ì´ë¨¸ ì´ˆê¸°í™”
        del countdown_timers[topic]

# ë©”ì‹œì§€ ìˆ˜ì‹  ë° ì²˜ë¦¬ ì‹œì‘
for message in consumer:
    consume_message(message)